{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(r'G:\\Kaggle\\Titanic\\train.csv',index_col=False)\n",
    "test_data = pd.read_csv(r'G:\\Kaggle\\Titanic\\test.csv',index_col=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "boys = []\n",
    "men = []\n",
    "women = []\n",
    "girls = []\n",
    "unwanted = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for ind in train_data.index:\n",
    "        if math.isnan(train_data['Age'][ind])==False:\n",
    "            name = train_data['Name'][ind]\n",
    "            if \"Mr\" in name and train_data['Sex'][ind]==\"male\" :\n",
    "                \n",
    "                men.append(train_data['Age'][ind])\n",
    "            elif \"Master\" in name:\n",
    "#                 \n",
    "                boys.append(train_data['Age'][ind])\n",
    "                \n",
    "            elif \"Mr\" in name and train_data['Sex'][ind]==\"female\":\n",
    "                \n",
    "                women.append(train_data['Age'][ind])\n",
    "            else:\n",
    "                if train_data['Parch'][ind] >1 and train_data['Parch'][ind] <3:\n",
    "                    \n",
    "                    girls.append(train_data['Age'][ind])\n",
    "                else:\n",
    "                    \n",
    "                    unwanted.append(train_data['Age'][ind])\n",
    "                    \n",
    "    boysAvg = np.array(boys).mean()\n",
    "    menAvg = np.array(men).mean() \n",
    "    womenAvg = np.array(women).mean()\n",
    "    girlsAvg = np.array(girls).mean()\n",
    "    unwantedAvg = np.array(unwanted).mean()\n",
    "    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.642857142857146"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "womenAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\LENOVO\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\LENOVO\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\LENOVO\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "C:\\Users\\LENOVO\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "for ind in train_data.index:\n",
    "    if math.isnan(train_data['Age'][ind]):\n",
    "        name = train_data['Name'][ind]\n",
    "        if \"Mrs\" in name:\n",
    "            train_data['Age'][ind]=womenAvg\n",
    "        elif \"Master\" in name:\n",
    "            train_data['Age'][ind]=boysAvg\n",
    "        elif \"Mr\" in name:\n",
    "            train_data['Age'][ind]=menAvg\n",
    "        else:\n",
    "            if train_data['Parch'][ind] >1 and train_data['Parch'][ind] <3:\n",
    "                train_data['Age'][ind]=girlsAvg\n",
    "            else:\n",
    "                train_data['Age'][ind]=unwantedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\LENOVO\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\LENOVO\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\LENOVO\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\LENOVO\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "for ind in test_data.index:\n",
    "    if math.isnan(test_data['Age'][ind]):\n",
    "        name = test_data['Name'][ind]\n",
    "        if \"Mrs\" in name:\n",
    "            test_data['Age'][ind]=womenAvg\n",
    "        elif \"Master\" in name:\n",
    "            test_data['Age'][ind]=boysAvg\n",
    "        elif \"Mr\" in name:\n",
    "            test_data['Age'][ind]=menAvg\n",
    "        else:\n",
    "            if test_data['Parch'][ind] >1 and test_data['Parch'][ind] <3:\n",
    "                test_data['Age'][ind]=girlsAvg\n",
    "            else:\n",
    "                test_data['Age'][ind]=unwantedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "passID = test_data['PassengerId']\n",
    "train_data=train_data.drop(['Name','Ticket','Fare','Cabin','Embarked','PassengerId'],axis=1)\n",
    "test_data=test_data.drop(['Name','Ticket','Fare','Cabin','Embarked','PassengerId'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>886</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>887</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>888</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>13.387097</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>889</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass     Sex        Age  SibSp  Parch\n",
       "0           0       3    male  22.000000      1      0\n",
       "1           1       1  female  38.000000      1      0\n",
       "2           1       3  female  26.000000      0      0\n",
       "3           1       1  female  35.000000      1      0\n",
       "4           0       3    male  35.000000      0      0\n",
       "..        ...     ...     ...        ...    ...    ...\n",
       "886         0       2    male  27.000000      0      0\n",
       "887         1       1  female  19.000000      0      0\n",
       "888         0       3  female  13.387097      1      2\n",
       "889         1       1    male  26.000000      0      0\n",
       "890         0       3    male  32.000000      0      0\n",
       "\n",
       "[891 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data=train_data.dropna(axis=0,how=\"any\", thresh=None, subset=None, inplace=False)\n",
    "#test_data=test_data.dropna(axis=0,how=\"any\", thresh=None, subset=None, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.409774</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.642857</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.409774</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>35.642857</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>27.220588</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.409774</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>32.409774</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.409774</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pclass     Sex        Age  SibSp  Parch\n",
       "0        3    male  34.500000      0      0\n",
       "1        3  female  47.000000      1      0\n",
       "2        2    male  62.000000      0      0\n",
       "3        3    male  27.000000      0      0\n",
       "4        3  female  22.000000      1      1\n",
       "5        3    male  14.000000      0      0\n",
       "6        3  female  30.000000      0      0\n",
       "7        2    male  26.000000      1      1\n",
       "8        3  female  18.000000      0      0\n",
       "9        3    male  21.000000      2      0\n",
       "10       3    male  32.409774      0      0\n",
       "11       1    male  46.000000      0      0\n",
       "12       1  female  23.000000      1      0\n",
       "13       2    male  63.000000      1      0\n",
       "14       1  female  47.000000      1      0\n",
       "15       2  female  24.000000      1      0\n",
       "16       2    male  35.000000      0      0\n",
       "17       3    male  21.000000      0      0\n",
       "18       3  female  27.000000      1      0\n",
       "19       3  female  45.000000      0      0\n",
       "20       1    male  55.000000      1      0\n",
       "21       3    male   9.000000      0      1\n",
       "22       1  female  35.642857      0      0\n",
       "23       1    male  21.000000      0      1\n",
       "24       1  female  48.000000      1      3\n",
       "25       3    male  50.000000      1      0\n",
       "26       1  female  22.000000      0      1\n",
       "27       3    male  22.500000      0      0\n",
       "28       1    male  41.000000      0      0\n",
       "29       3    male  32.409774      2      0\n",
       "30       2    male  50.000000      1      0\n",
       "31       2    male  24.000000      2      0\n",
       "32       3  female  33.000000      1      2\n",
       "33       3  female  35.642857      1      2\n",
       "34       1    male  30.000000      1      0\n",
       "35       3    male  18.500000      0      0\n",
       "36       3  female  27.220588      0      0\n",
       "37       3  female  21.000000      0      0\n",
       "38       3    male  25.000000      0      0\n",
       "39       3    male  32.409774      0      0\n",
       "40       3    male  39.000000      0      1\n",
       "41       1    male  32.409774      0      0\n",
       "42       3    male  41.000000      0      0\n",
       "43       2  female  30.000000      0      0\n",
       "44       1  female  45.000000      1      0\n",
       "45       3    male  25.000000      0      0\n",
       "46       1    male  45.000000      0      0\n",
       "47       3    male  32.409774      0      0\n",
       "48       1  female  60.000000      0      0\n",
       "49       3  female  36.000000      0      2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Sex']=np.where(train_data['Sex']=='male',0,1)\n",
    "test_data['Sex']=np.where(test_data['Sex']=='male',0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>886</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>887</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>888</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13.387097</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>889</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex        Age  SibSp  Parch\n",
       "0           0       3    0  22.000000      1      0\n",
       "1           1       1    1  38.000000      1      0\n",
       "2           1       3    1  26.000000      0      0\n",
       "3           1       1    1  35.000000      1      0\n",
       "4           0       3    0  35.000000      0      0\n",
       "..        ...     ...  ...        ...    ...    ...\n",
       "886         0       2    0  27.000000      0      0\n",
       "887         1       1    1  19.000000      0      0\n",
       "888         0       3    1  13.387097      1      2\n",
       "889         1       1    0  26.000000      0      0\n",
       "890         0       3    0  32.000000      0      0\n",
       "\n",
       "[891 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "atrain_lab = train_data['Survived']\n",
    "train_data = train_data.drop(['Survived'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>886</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>887</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>888</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13.387097</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>889</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex        Age  SibSp  Parch\n",
       "0         3    0  22.000000      1      0\n",
       "1         1    1  38.000000      1      0\n",
       "2         3    1  26.000000      0      0\n",
       "3         1    1  35.000000      1      0\n",
       "4         3    0  35.000000      0      0\n",
       "..      ...  ...        ...    ...    ...\n",
       "886       2    0  27.000000      0      0\n",
       "887       1    1  19.000000      0      0\n",
       "888       3    1  13.387097      1      2\n",
       "889       1    0  26.000000      0      0\n",
       "890       3    0  32.000000      0      0\n",
       "\n",
       "[891 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lab = np.array(atrain_lab)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train_samples = scaler.fit_transform(train_data)\n",
    "scaled_test = scaler.fit_transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.27117366, 0.125     , 0.        ],\n",
       "       [0.        , 1.        , 0.4722292 , 0.125     , 0.        ],\n",
       "       [1.        , 1.        , 0.32143755, 0.        , 0.        ],\n",
       "       ...,\n",
       "       [1.        , 1.        , 0.16294417, 0.125     , 0.33333333],\n",
       "       [0.        , 0.        , 0.32143755, 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.39683338, 0.        , 0.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(units=16, input_shape=(5,), activation='relu'),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dense(units=64, activation='relu'),\n",
    "    Dense(units=64, activation='relu'),\n",
    "    Dense(units=128, activation='relu'),\n",
    "    Dense(units=256, activation='relu'),\n",
    "    Dense(units=256, activation='relu'),\n",
    "    Dense(units=256, activation='relu'),\n",
    "    Dense(units=128, activation='relu'),\n",
    "    Dense(units=128, activation='relu'),\n",
    "    Dense(units=128, activation='relu'),\n",
    "    Dense(units=64, activation='relu'),\n",
    "    Dense(units=64, activation='relu'),\n",
    "    Dense(units=2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                96        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 258,306\n",
      "Trainable params: 258,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.00001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 801 samples, validate on 90 samples\n",
      "Epoch 1/100\n",
      "801/801 - 2s - loss: 0.6918 - accuracy: 0.6155 - val_loss: 0.6900 - val_accuracy: 0.6222\n",
      "Epoch 2/100\n",
      "801/801 - 0s - loss: 0.6884 - accuracy: 0.6155 - val_loss: 0.6856 - val_accuracy: 0.6222\n",
      "Epoch 3/100\n",
      "801/801 - 0s - loss: 0.6829 - accuracy: 0.6804 - val_loss: 0.6780 - val_accuracy: 0.7667\n",
      "Epoch 4/100\n",
      "801/801 - 0s - loss: 0.6737 - accuracy: 0.7528 - val_loss: 0.6654 - val_accuracy: 0.8000\n",
      "Epoch 5/100\n",
      "801/801 - 0s - loss: 0.6582 - accuracy: 0.7603 - val_loss: 0.6453 - val_accuracy: 0.8000\n",
      "Epoch 6/100\n",
      "801/801 - 0s - loss: 0.6331 - accuracy: 0.7690 - val_loss: 0.6120 - val_accuracy: 0.8000\n",
      "Epoch 7/100\n",
      "801/801 - 0s - loss: 0.5976 - accuracy: 0.7803 - val_loss: 0.5733 - val_accuracy: 0.8000\n",
      "Epoch 8/100\n",
      "801/801 - 0s - loss: 0.5602 - accuracy: 0.7890 - val_loss: 0.5405 - val_accuracy: 0.8000\n",
      "Epoch 9/100\n",
      "801/801 - 0s - loss: 0.5293 - accuracy: 0.7978 - val_loss: 0.5180 - val_accuracy: 0.8000\n",
      "Epoch 10/100\n",
      "801/801 - 0s - loss: 0.5097 - accuracy: 0.8090 - val_loss: 0.5042 - val_accuracy: 0.7889\n",
      "Epoch 11/100\n",
      "801/801 - 0s - loss: 0.4958 - accuracy: 0.8090 - val_loss: 0.4923 - val_accuracy: 0.8000\n",
      "Epoch 12/100\n",
      "801/801 - 0s - loss: 0.4851 - accuracy: 0.8115 - val_loss: 0.4822 - val_accuracy: 0.7889\n",
      "Epoch 13/100\n",
      "801/801 - 0s - loss: 0.4752 - accuracy: 0.8065 - val_loss: 0.4731 - val_accuracy: 0.7889\n",
      "Epoch 14/100\n",
      "801/801 - 0s - loss: 0.4680 - accuracy: 0.8077 - val_loss: 0.4653 - val_accuracy: 0.7889\n",
      "Epoch 15/100\n",
      "801/801 - 0s - loss: 0.4620 - accuracy: 0.8090 - val_loss: 0.4583 - val_accuracy: 0.8000\n",
      "Epoch 16/100\n",
      "801/801 - 0s - loss: 0.4546 - accuracy: 0.8090 - val_loss: 0.4528 - val_accuracy: 0.8000\n",
      "Epoch 17/100\n",
      "801/801 - 0s - loss: 0.4504 - accuracy: 0.8090 - val_loss: 0.4471 - val_accuracy: 0.8000\n",
      "Epoch 18/100\n",
      "801/801 - 0s - loss: 0.4447 - accuracy: 0.8102 - val_loss: 0.4439 - val_accuracy: 0.8000\n",
      "Epoch 19/100\n",
      "801/801 - 0s - loss: 0.4420 - accuracy: 0.8052 - val_loss: 0.4386 - val_accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "801/801 - 0s - loss: 0.4392 - accuracy: 0.8115 - val_loss: 0.4337 - val_accuracy: 0.7889\n",
      "Epoch 21/100\n",
      "801/801 - 0s - loss: 0.4382 - accuracy: 0.8127 - val_loss: 0.4316 - val_accuracy: 0.8000\n",
      "Epoch 22/100\n",
      "801/801 - 0s - loss: 0.4347 - accuracy: 0.8140 - val_loss: 0.4328 - val_accuracy: 0.8000\n",
      "Epoch 23/100\n",
      "801/801 - 1s - loss: 0.4352 - accuracy: 0.8102 - val_loss: 0.4252 - val_accuracy: 0.7889\n",
      "Epoch 24/100\n",
      "801/801 - 1s - loss: 0.4318 - accuracy: 0.8127 - val_loss: 0.4239 - val_accuracy: 0.8000\n",
      "Epoch 25/100\n",
      "801/801 - 1s - loss: 0.4308 - accuracy: 0.8115 - val_loss: 0.4208 - val_accuracy: 0.7889\n",
      "Epoch 26/100\n",
      "801/801 - 0s - loss: 0.4308 - accuracy: 0.8065 - val_loss: 0.4181 - val_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "801/801 - 0s - loss: 0.4284 - accuracy: 0.8115 - val_loss: 0.4189 - val_accuracy: 0.8000\n",
      "Epoch 28/100\n",
      "801/801 - 0s - loss: 0.4289 - accuracy: 0.8040 - val_loss: 0.4165 - val_accuracy: 0.8000\n",
      "Epoch 29/100\n",
      "801/801 - 0s - loss: 0.4265 - accuracy: 0.8115 - val_loss: 0.4124 - val_accuracy: 0.8000\n",
      "Epoch 30/100\n",
      "801/801 - 0s - loss: 0.4253 - accuracy: 0.8165 - val_loss: 0.4121 - val_accuracy: 0.7889\n",
      "Epoch 31/100\n",
      "801/801 - 0s - loss: 0.4254 - accuracy: 0.8127 - val_loss: 0.4102 - val_accuracy: 0.7889\n",
      "Epoch 32/100\n",
      "801/801 - 0s - loss: 0.4240 - accuracy: 0.8127 - val_loss: 0.4098 - val_accuracy: 0.8000\n",
      "Epoch 33/100\n",
      "801/801 - 0s - loss: 0.4242 - accuracy: 0.8115 - val_loss: 0.4131 - val_accuracy: 0.8000\n",
      "Epoch 34/100\n",
      "801/801 - 0s - loss: 0.4254 - accuracy: 0.8115 - val_loss: 0.4068 - val_accuracy: 0.7889\n",
      "Epoch 35/100\n",
      "801/801 - 0s - loss: 0.4234 - accuracy: 0.8102 - val_loss: 0.4079 - val_accuracy: 0.8000\n",
      "Epoch 36/100\n",
      "801/801 - 0s - loss: 0.4234 - accuracy: 0.8152 - val_loss: 0.4032 - val_accuracy: 0.7889\n",
      "Epoch 37/100\n",
      "801/801 - 0s - loss: 0.4218 - accuracy: 0.8152 - val_loss: 0.4054 - val_accuracy: 0.8000\n",
      "Epoch 38/100\n",
      "801/801 - 0s - loss: 0.4219 - accuracy: 0.8152 - val_loss: 0.4007 - val_accuracy: 0.7889\n",
      "Epoch 39/100\n",
      "801/801 - 0s - loss: 0.4210 - accuracy: 0.8140 - val_loss: 0.4007 - val_accuracy: 0.7889\n",
      "Epoch 40/100\n",
      "801/801 - 1s - loss: 0.4207 - accuracy: 0.8165 - val_loss: 0.4009 - val_accuracy: 0.7889\n",
      "Epoch 41/100\n",
      "801/801 - 1s - loss: 0.4228 - accuracy: 0.8127 - val_loss: 0.4013 - val_accuracy: 0.8000\n",
      "Epoch 42/100\n",
      "801/801 - 1s - loss: 0.4197 - accuracy: 0.8152 - val_loss: 0.3987 - val_accuracy: 0.7889\n",
      "Epoch 43/100\n",
      "801/801 - 0s - loss: 0.4187 - accuracy: 0.8152 - val_loss: 0.4024 - val_accuracy: 0.8111\n",
      "Epoch 44/100\n",
      "801/801 - 0s - loss: 0.4202 - accuracy: 0.8115 - val_loss: 0.3998 - val_accuracy: 0.8111\n",
      "Epoch 45/100\n",
      "801/801 - 0s - loss: 0.4201 - accuracy: 0.8127 - val_loss: 0.3952 - val_accuracy: 0.7889\n",
      "Epoch 46/100\n",
      "801/801 - 0s - loss: 0.4184 - accuracy: 0.8165 - val_loss: 0.3937 - val_accuracy: 0.7889\n",
      "Epoch 47/100\n",
      "801/801 - 0s - loss: 0.4177 - accuracy: 0.8165 - val_loss: 0.3940 - val_accuracy: 0.8000\n",
      "Epoch 48/100\n",
      "801/801 - 0s - loss: 0.4176 - accuracy: 0.8165 - val_loss: 0.3940 - val_accuracy: 0.8000\n",
      "Epoch 49/100\n",
      "801/801 - 0s - loss: 0.4177 - accuracy: 0.8177 - val_loss: 0.3951 - val_accuracy: 0.8111\n",
      "Epoch 50/100\n",
      "801/801 - 0s - loss: 0.4179 - accuracy: 0.8152 - val_loss: 0.3929 - val_accuracy: 0.8000\n",
      "Epoch 51/100\n",
      "801/801 - 0s - loss: 0.4176 - accuracy: 0.8177 - val_loss: 0.3977 - val_accuracy: 0.8333\n",
      "Epoch 52/100\n",
      "801/801 - 0s - loss: 0.4176 - accuracy: 0.8140 - val_loss: 0.3923 - val_accuracy: 0.8222\n",
      "Epoch 53/100\n",
      "801/801 - 0s - loss: 0.4174 - accuracy: 0.8152 - val_loss: 0.3922 - val_accuracy: 0.8222\n",
      "Epoch 54/100\n",
      "801/801 - 0s - loss: 0.4166 - accuracy: 0.8140 - val_loss: 0.3947 - val_accuracy: 0.8444\n",
      "Epoch 55/100\n",
      "801/801 - 0s - loss: 0.4158 - accuracy: 0.8165 - val_loss: 0.3886 - val_accuracy: 0.8222\n",
      "Epoch 56/100\n",
      "801/801 - 1s - loss: 0.4163 - accuracy: 0.8215 - val_loss: 0.3904 - val_accuracy: 0.8333\n",
      "Epoch 57/100\n",
      "801/801 - 1s - loss: 0.4158 - accuracy: 0.8240 - val_loss: 0.3931 - val_accuracy: 0.8444\n",
      "Epoch 58/100\n",
      "801/801 - 1s - loss: 0.4152 - accuracy: 0.8277 - val_loss: 0.3895 - val_accuracy: 0.8333\n",
      "Epoch 59/100\n",
      "801/801 - 1s - loss: 0.4153 - accuracy: 0.8227 - val_loss: 0.3859 - val_accuracy: 0.8222\n",
      "Epoch 60/100\n",
      "801/801 - 1s - loss: 0.4151 - accuracy: 0.8202 - val_loss: 0.3911 - val_accuracy: 0.8444\n",
      "Epoch 61/100\n",
      "801/801 - 1s - loss: 0.4143 - accuracy: 0.8240 - val_loss: 0.3838 - val_accuracy: 0.8333\n",
      "Epoch 62/100\n",
      "801/801 - 0s - loss: 0.4151 - accuracy: 0.8227 - val_loss: 0.3875 - val_accuracy: 0.8333\n",
      "Epoch 63/100\n",
      "801/801 - 0s - loss: 0.4145 - accuracy: 0.8252 - val_loss: 0.3898 - val_accuracy: 0.8444\n",
      "Epoch 64/100\n",
      "801/801 - 0s - loss: 0.4137 - accuracy: 0.8252 - val_loss: 0.3855 - val_accuracy: 0.8333\n",
      "Epoch 65/100\n",
      "801/801 - 0s - loss: 0.4139 - accuracy: 0.8252 - val_loss: 0.3856 - val_accuracy: 0.8333\n",
      "Epoch 66/100\n",
      "801/801 - 0s - loss: 0.4140 - accuracy: 0.8277 - val_loss: 0.3833 - val_accuracy: 0.8333\n",
      "Epoch 67/100\n",
      "801/801 - 0s - loss: 0.4155 - accuracy: 0.8252 - val_loss: 0.3880 - val_accuracy: 0.8444\n",
      "Epoch 68/100\n",
      "801/801 - 0s - loss: 0.4143 - accuracy: 0.8265 - val_loss: 0.3886 - val_accuracy: 0.8444\n",
      "Epoch 69/100\n",
      "801/801 - 0s - loss: 0.4136 - accuracy: 0.8340 - val_loss: 0.3838 - val_accuracy: 0.8333\n",
      "Epoch 70/100\n",
      "801/801 - 1s - loss: 0.4144 - accuracy: 0.8252 - val_loss: 0.3900 - val_accuracy: 0.8444\n",
      "Epoch 71/100\n",
      "801/801 - 1s - loss: 0.4127 - accuracy: 0.8290 - val_loss: 0.3824 - val_accuracy: 0.8333\n",
      "Epoch 72/100\n",
      "801/801 - 1s - loss: 0.4133 - accuracy: 0.8302 - val_loss: 0.3816 - val_accuracy: 0.8333\n",
      "Epoch 73/100\n",
      "801/801 - 1s - loss: 0.4131 - accuracy: 0.8315 - val_loss: 0.3819 - val_accuracy: 0.8333\n",
      "Epoch 74/100\n",
      "801/801 - 1s - loss: 0.4124 - accuracy: 0.8265 - val_loss: 0.3881 - val_accuracy: 0.8444\n",
      "Epoch 75/100\n",
      "801/801 - 1s - loss: 0.4139 - accuracy: 0.8315 - val_loss: 0.3822 - val_accuracy: 0.8333\n",
      "Epoch 76/100\n",
      "801/801 - 0s - loss: 0.4149 - accuracy: 0.8240 - val_loss: 0.3825 - val_accuracy: 0.8333\n",
      "Epoch 77/100\n",
      "801/801 - 0s - loss: 0.4121 - accuracy: 0.8290 - val_loss: 0.3789 - val_accuracy: 0.8444\n",
      "Epoch 78/100\n",
      "801/801 - 0s - loss: 0.4119 - accuracy: 0.8265 - val_loss: 0.3825 - val_accuracy: 0.8333\n",
      "Epoch 79/100\n",
      "801/801 - 0s - loss: 0.4123 - accuracy: 0.8265 - val_loss: 0.3835 - val_accuracy: 0.8333\n",
      "Epoch 80/100\n",
      "801/801 - 0s - loss: 0.4104 - accuracy: 0.8302 - val_loss: 0.3779 - val_accuracy: 0.8444\n",
      "Epoch 81/100\n",
      "801/801 - 0s - loss: 0.4127 - accuracy: 0.8315 - val_loss: 0.3791 - val_accuracy: 0.8333\n",
      "Epoch 82/100\n",
      "801/801 - 0s - loss: 0.4110 - accuracy: 0.8302 - val_loss: 0.3777 - val_accuracy: 0.8444\n",
      "Epoch 83/100\n",
      "801/801 - 0s - loss: 0.4120 - accuracy: 0.8315 - val_loss: 0.3777 - val_accuracy: 0.8333\n",
      "Epoch 84/100\n",
      "801/801 - 0s - loss: 0.4124 - accuracy: 0.8315 - val_loss: 0.3760 - val_accuracy: 0.8333\n",
      "Epoch 85/100\n",
      "801/801 - 1s - loss: 0.4098 - accuracy: 0.8290 - val_loss: 0.3781 - val_accuracy: 0.8333\n",
      "Epoch 86/100\n",
      "801/801 - 1s - loss: 0.4120 - accuracy: 0.8240 - val_loss: 0.3783 - val_accuracy: 0.8444\n",
      "Epoch 87/100\n",
      "801/801 - 1s - loss: 0.4106 - accuracy: 0.8240 - val_loss: 0.3870 - val_accuracy: 0.8556\n",
      "Epoch 88/100\n",
      "801/801 - 1s - loss: 0.4117 - accuracy: 0.8277 - val_loss: 0.3826 - val_accuracy: 0.8444\n",
      "Epoch 89/100\n",
      "801/801 - 1s - loss: 0.4125 - accuracy: 0.8290 - val_loss: 0.3854 - val_accuracy: 0.8556\n",
      "Epoch 90/100\n",
      "801/801 - 1s - loss: 0.4119 - accuracy: 0.8327 - val_loss: 0.3817 - val_accuracy: 0.8444\n",
      "Epoch 91/100\n",
      "801/801 - 0s - loss: 0.4102 - accuracy: 0.8265 - val_loss: 0.3742 - val_accuracy: 0.8333\n",
      "Epoch 92/100\n",
      "801/801 - 0s - loss: 0.4100 - accuracy: 0.8290 - val_loss: 0.3830 - val_accuracy: 0.8556\n",
      "Epoch 93/100\n",
      "801/801 - 0s - loss: 0.4121 - accuracy: 0.8277 - val_loss: 0.3776 - val_accuracy: 0.8444\n",
      "Epoch 94/100\n",
      "801/801 - 0s - loss: 0.4110 - accuracy: 0.8302 - val_loss: 0.3780 - val_accuracy: 0.8444\n",
      "Epoch 95/100\n",
      "801/801 - 0s - loss: 0.4090 - accuracy: 0.8302 - val_loss: 0.3795 - val_accuracy: 0.8444\n",
      "Epoch 96/100\n",
      "801/801 - 0s - loss: 0.4116 - accuracy: 0.8302 - val_loss: 0.3813 - val_accuracy: 0.8444\n",
      "Epoch 97/100\n",
      "801/801 - 0s - loss: 0.4092 - accuracy: 0.8277 - val_loss: 0.3728 - val_accuracy: 0.8333\n",
      "Epoch 98/100\n",
      "801/801 - 0s - loss: 0.4112 - accuracy: 0.8265 - val_loss: 0.3758 - val_accuracy: 0.8444\n",
      "Epoch 99/100\n",
      "801/801 - 0s - loss: 0.4093 - accuracy: 0.8290 - val_loss: 0.3728 - val_accuracy: 0.8556\n",
      "Epoch 100/100\n",
      "801/801 - 1s - loss: 0.4088 - accuracy: 0.8265 - val_loss: 0.3768 - val_accuracy: 0.8444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22007602b48>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_train_samples, y=train_lab,validation_split=0.1, batch_size=10, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history.history['accuracy'])\n",
    "plt.plot(model.history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd5jU9bX48feZ2Z3tfZcFdoFFWBRQii6IvSs2bKhYYkmiyU38mZiq3uQmMcmNNze5JiamoCFq7MESNHbFLghYkKL0haVuZ/vOzpzfH59BlmWAbcPszp7X88zDzLfN+TIwZz5dVBVjjDGmI0+0AzDGGNM3WYIwxhgTliUIY4wxYVmCMMYYE5YlCGOMMWFZgjDGGBOWJQhjeoGI3C8iv+jksRtE5PSeXseYSLMEYYwxJixLEMYYY8KyBGEGjFDVzvdFZKmINIjI30QkX0ReEJE6EXlVRLLaHT9DRJaLSI2IvCEiY9vtmywiH4bOexxI7PBe54nIx6Fz3xORCd2M+QYRWSMiVSIyT0SGhraLiNwlIjtEpDZ0T4eH9p0jIitCsW0Wke916y/MDHiWIMxAcwlwBjAGOB94AbgdyMX9f7gZQETGAI8C3wbygOeBZ0XEJyI+4BngH0A28M/QdQmdeyQwB/gakAP8FZgnIgldCVRETgV+BVwGDAFKgcdCu88ETgzdRyZwOVAZ2vc34GuqmgYcDrzelfc1ZhdLEGag+YOqblfVzcDbwEJV/UhVW4Cngcmh4y4H/q2qr6iqH/gNkAQcC0wD4oHfqapfVecCi9q9xw3AX1V1oaoGVPUBoCV0XldcBcxR1Q9D8d0GHCMiRYAfSAMOA0RVV6rq1tB5fmCciKSrarWqftjF9zUGsARhBp7t7Z43hXmdGno+FPeLHQBVDQKbgILQvs2650yXpe2ejwC+G6peqhGRGmBY6Lyu6BhDPa6UUKCqrwN/BO4BtovIbBFJDx16CXAOUCoib4rIMV18X2MASxDG7MsW3Bc94Or8cV/ym4GtQEFo2y7D2z3fBPxSVTPbPZJV9dEexpCCq7LaDKCqd6vqUcB4XFXT90PbF6nqBcAgXFXYE118X2MASxDG7MsTwLkicpqIxAPfxVUTvQe8D7QBN4tInIhcDExtd+69wNdF5OhQY3KKiJwrImldjOER4HoRmRRqv/hvXJXYBhGZErp+PNAANAOBUBvJVSKSEaoa2wkEevD3YAYwSxDGhKGqnwNXA38AKnAN2ueraquqtgIXA9cB1bj2iqfanbsY1w7xx9D+NaFjuxrDa8CPgSdxpZZRwKzQ7nRcIqrGVUNV4tpJAL4EbBCRncDXQ/dhTJeJLRhkjDEmHCtBGGOMCcsShDHGmLAsQRhjjAnLEoQxxpiw4qIdQG/Jzc3VoqKiaIdhjDH9ypIlSypUNS/cvphJEEVFRSxevDjaYRhjTL8iIqX72hfRKiYRmS4in4dmo7w1zP67QjNefiwiq0JTEuzad62IrA49ro1knMYYY/YWsRKEiHhx88ScAZQBi0Rknqqu2HWMqt7S7vj/R2iiNBHJBn4ClAAKLAmdWx2peI0xxuwpkiWIqcAaVV0XGnn6GHDBfo6/Aje9MsBZwCuqWhVKCq8A0yMYqzHGmA4i2QZRgJu0bJcy4OhwB4rICGAku+etD3duQZjzbgRuBBg+fHjH3fj9fsrKymhubu5G+P1LYmIihYWFxMfHRzsUY0yMiGSCkDDb9jWvxyxgrqrumlSsU+eq6mxgNkBJScle+8vKykhLS6OoqIg9J96MLapKZWUlZWVljBw5MtrhGGNiRCSrmMpw0yPvUoibvjicWeyuXurqufvU3NxMTk5OTCcHABEhJydnQJSUjDEHTyQTxCKgWERGhpZonAXM63iQiBwKZOGmUN7lJeBMEckKrRF8Zmhbl8V6cthloNynMebgiViCUNU24CbcF/tK4AlVXS4id4jIjHaHXgE81n51LlWtAn6OSzKLgDtC2yIRJ1trm2jx25T5xhjTXkTHQajq86o6RlVHqeovQ9v+S1XntTvmp6q61xgJVZ2jqqNDj79HKsbWtiCehh2s31FDRX0LvT39eU1NDX/605+6fN4555xDTU3NgQ80xpgIGfBzMSXgZxA1jJKtVNTsZF1FA61twV67/r4SRCCw/xLL888/T2ZmZq/FYYwxXTXgEwTxiUjuaOIkyBjvVmhtZH1FA22B3kkSt956K2vXrmXSpElMmTKFU045hSuvvJIjjjgCgAsvvJCjjjqK8ePHM3v27C/OKyoqoqKigg0bNjB27FhuuOEGxo8fz5lnnklTU1OvxGaMMfsTM3MxHcjPnl3Oii07932ABqGtCXQ7zfhQ8ZIU793vNccNTecn54/f7zF33nkny5Yt4+OPP+aNN97g3HPPZdmyZV90R50zZw7Z2dk0NTUxZcoULrnkEnJycva4xurVq3n00Ue59957ueyyy3jyySe5+mpbRdIYE1lWgthFPBCfDOIhET8aVJoj0HA9derUPcYq3H333UycOJFp06axadMmVq9evdc5I0eOZNKkSQAcddRRbNiwodfjMsaYjgZMCeJAv/S/0FIPlatp9mWzqjmDvLQEhmQk9VocKSkpXzx/4403ePXVV3n//fdJTk7m5JNPDjuWISEh4YvnXq/XqpiMMQeFlSA6SkiFlDwSW6sYnBigor61R43WaWlp1NXVhd1XW1tLVlYWycnJfPbZZyxYsKDb72OMMb1twJQguiRtCDTXkhvYTjlD2b6zmWHZyd26VE5ODscddxyHH344SUlJ5Ofnf7Fv+vTp/OUvf2HChAkceuihTJs2rbfuwBhjekx6u99/tJSUlGjHBYNWrlzJ2LFju3fB5p1QtZa6+Fw2tKRRnJ9G4gEaraOtR/drjBmQRGSJqpaE22dVTPuSmA4J6aQGavF4hG21Ns+RMWZgsQSxP8k5SNBPYWIrO5v9NLS0RTsiY4w5aCxB7E9iOnjiSNedxHk9lNe1RDsiY4w5aCxB7I94XCmiZSc5iUJdSxuBYGy02RhjzIFYgjiQZDeqOYs6VJW6Zn+UAzLGmIPDEsSBxCWAL4341iriPUJtkyUIY8zAYAmiM1JykICfPF8rdc1tBCNYzZSamhqxaxtjTFdYguiMxAzwxJFBHUFV6q03kzFmALCR1J0hHvClEddaj9eTQ22Tn/Sk+E6d+sMf/pARI0bwjW98A4Cf/vSniAhvvfUW1dXV+P1+fvGLX3DBBRdE8g6MMabLBk6CeOFW2PZp988PtiJtLYz2JNEWBPV5kcET4Ow793varFmz+Pa3v/1FgnjiiSd48cUXueWWW0hPT6eiooJp06YxY8YMW1faGNOnDJwE0VMSB7QQRxC/eggEtVN/eZMnT2bHjh1s2bKF8vJysrKyGDJkCLfccgtvvfUWHo+HzZs3s337dgYPHhzpuzDGmE4bOAniAL/0D0gVti/D40tjQ1MWWcnxFGR1bgK/mTNnMnfuXLZt28asWbN4+OGHKS8vZ8mSJcTHx1NUVBR2mm9jjIkma6TuLBHwpSL+BlIS4mho7fxiQrNmzeKxxx5j7ty5zJw5k9raWgYNGkR8fDzz58+ntLQ0goEbY0z3DJwSRG/wpUJzDakJAbY1BwkGFY/nwO0G48ePp66ujoKCAoYMGcJVV13F+eefT0lJCZMmTeKwww47CMEbY0zXRDRBiMh04PeAF7hPVfeq5xGRy4CfAgp8oqpXhrYHgF2tyhtVdUYkY+2UBDdGIYVmFB9N/gApCZ37K/z0090N5Lm5ubz//vthj6uvr+95nMYY0wsiliBExAvcA5wBlAGLRGSeqq5od0wxcBtwnKpWi8igdpdoUtVJkYqvW+ISQbwkBJugiwnCGGP6m0i2QUwF1qjqOlVtBR4DOnb2vwG4R1WrAVR1RwTj6TkRSEjF468nzuOhqQvtEMYY099EMkEUAJvavS4LbWtvDDBGRN4VkQWhKqldEkVkcWj7heHeQERuDB2zuLy8PGwQvb5ini8VCbSSGh+kyd93EkSsrAxojOk7IpkgwrXedvwWiwOKgZOBK4D7RCQztG94aBm8K4HficiovS6mOltVS1S1JC8vb683S0xMpLKysne/PH2uHSLd00KLPxjReZk6S1WprKwkMTEx2qEYY2JIJCvQy4Bh7V4XAlvCHLNAVf3AehH5HJcwFqnqFgBVXScibwCTgbVdCaCwsJCysjL2VbroFlXYWUGbt4Ft/mSC1Qn44qLfWzgxMZHCwsJoh2GMiSGRTBCLgGIRGQlsBmbhSgPtPYMrOdwvIrm4Kqd1IpIFNKpqS2j7ccCvuxpAfHw8I0eO7Mk9hPfgbbQ01HB+6Q/4xYWHc/W0Eb3/HsYYE2UR++mrqm3ATcBLwErgCVVdLiJ3iMiuLqsvAZUisgKYD3xfVSuBscBiEfkktP3O9r2foi6nGF/NOjIS41i+pTba0RhjTEREtI+mqj4PPN9h23+1e67Ad0KP9se8BxwRydh6JGc00rKT44Yon262BGGMiU3Rrzzvj3JGA3BMVjWfb6ujpa3v9GYyxpjeYgmiO3Jch6oJiRX4A8rq7Tb62RgTeyxBdEfmcPDEU8RWAKtmMsbEJEsQ3eHxQvYhpDeWkpYYxzJLEMaYGGQJortyi5HKNYwfms7yLTujHY0xxvQ6SxDdlTMKqtYxOjeJDZUN0Y7GGGN6nSWI7soZDYFWxqfspKbRT22jP9oRGWNMr7IE0V2hrq7FcdsBKK2yUoQxJrZYguiuUIIYFnTTS22obIxmNMYY0+ssQXRXSh4kpJPT7GY0L62wEoQxJrZYguguEcgZRVzNWganJ1oJwhgTcyxB9EROMVSsYXhOMqXWk8kYE2MsQfREzmio3cToLC+lVVaCMMbEFksQPZEzClCOSK6ivK6Fhpa2aEdkjDG9xhJET4R6Mo3xhrq6WjuEMSaGWILoidCsrgXBzQDWDmGMiSmWIHoiIQ1SB5Md6upqPZmMMbHEEkRP5YzGV7OWnBQfG200tTEmhliC6KmsIqguZUROMhsqrARhjIkdliB6KmsE1G+jOCvO2iCMMTHFEkRPZY4AYFxKLVtqm2n22/rUxpjYYAmip7Jcgij2VQKwyQbMGWNiREQThIhMF5HPRWSNiNy6j2MuE5EVIrJcRB5pt/1aEVkdelwbyTh7JFSCGCblgI2FMMbEjrhIXVhEvMA9wBlAGbBIROap6op2xxQDtwHHqWq1iAwKbc8GfgKUAAosCZ1bHal4uy01H7wJ5LVtB0bZ6nLGmJgRyRLEVGCNqq5T1VbgMeCCDsfcANyz64tfVXeEtp8FvKKqVaF9rwDTIxhr93k8kDmchIZNpCfGWQnCGBMzIpkgCoBN7V6Xhba1NwYYIyLvisgCEZnehXMRkRtFZLGILC4vL+/F0LsoczhSXcqInBQrQRhjYkYkE4SE2aYdXscBxcDJwBXAfSKS2clzUdXZqlqiqiV5eXk9DLcHskZAjRsLYSUIY0ysiGSCKAOGtXtdCGwJc8y/VNWvquuBz3EJozPn9h2ZI6CpmtHpQbbUNNEWCEY7ImOM6bFIJohFQLGIjBQRHzALmNfhmGeAUwBEJBdX5bQOeAk4U0SyRCQLODO0rW8KdXU9LLGatqCytbY5ygEZY0zPRSxBqGobcBPui30l8ISqLheRO0RkRuiwl4BKEVkBzAe+r6qVqloF/ByXZBYBd4S29U2hrq5FXtcOYmMhjDGxIGLdXAFU9Xng+Q7b/qvdcwW+E3p0PHcOMCeS8fWarCIA8oPbgQw2VjVybFQDMsaYnrOR1L0hKQt8aWS0bCXOI2y0EoQxJgZYgugNIpA1Ak/NRgqykixBGGNigiWI3pI5HGpKGZ6dbG0QxpiYYAmit2SOgOpShlkJwhgTIyxB9JasEeBvYExaK9WNfnY2+6MdkTHG9IgliN6SadN+G2NiiyWI3pK1a9pvN9/gpqqmaEZjjDE9Zgmit4RKEHmBXQnCShDGmP7NEkRvSUiF5ByS6jeRkRRvDdXGmH7PEkRvCnV1HZZtPZmMMf2fJYjelFUE1RtsLIQxJiZYguhN2aOgupQRmT7KqpsIBPdawsIYY/oNSxC9KWc0aICxiZW0BoJs32nTfhtj+i9LEL0ptxiAUZ6tANYOYYzp1yxB9KacUQAMbdsMWIIwxvRvliB6U1IWJOeS0ViKR2wshDGmf7ME0dtyi/FUrWVoZpIlCGNMv2YJorfljIKK1QzPTrYqJmNMv2YJorflFEPDDoozgpYgjDH9miWI3pYzGoCJSRVU1LdS22jTfhtj+idLEL0t1NX10LhtAKwpr4tmNMYY022WIHpb1kgQDwVB19V1zY76KAdkjDHdE9EEISLTReRzEVkjIreG2X+diJSLyMehx1fb7Qu02z4vknH2qjgfZI4gvaEUX5zHEoQxpt+Ki9SFRcQL3AOcAZQBi0Rknqqu6HDo46p6U5hLNKnqpEjFF1G5xXgq13BIboolCGNMvxXJEsRUYI2qrlPVVuAx4IIIvl/fkTMaqtZSnJfMmnJLEMaY/imSCaIA2NTudVloW0eXiMhSEZkrIsPabU8UkcUiskBELgz3BiJyY+iYxeXl5b0Yeg/ljAZ/I5MymyirbqKpNRDtiIwxpssimSAkzLaO818/CxSp6gTgVeCBdvuGq2oJcCXwOxEZtdfFVGeraomqluTl5fVW3D0X6sk0PmEHqrDWShHGmH4okgmiDGhfIigEtrQ/QFUrVbUl9PJe4Kh2+7aE/lwHvAFMjmCsvSs0FmIkblZXSxDGmP4okgliEVAsIiNFxAfMAvbojSQiQ9q9nAGsDG3PEpGE0PNc4DigY+N235U2BOJTyGlxk/ZZQ7Uxpj+KWC8mVW0TkZuAlwAvMEdVl4vIHcBiVZ0H3CwiM4A2oAq4LnT6WOCvIhLEJbE7w/R+6rtEIGcUcVVrGZFzriUIY0y/1KkEISLfAv4O1AH34ap7blXVl/d3nqo+DzzfYdt/tXt+G3BbmPPeA47oTGx9Vm4xlC1iVF6qJQhjTL/U2SqmL6vqTuBMIA+4HrgzYlHFgkHjoGYjh2cH2FDZQFsgGO2IjDGmSzqbIHb1SDoH+LuqfkL4Xkpml8IpAJR41+EPKKU2s6sxpp/pbIJYIiIv4xLESyKSBthP4v0pOArEw2j/SgBWb7dqJmNM/9LZRuqvAJOAdaraKCLZuGomsy8JqTBoPLnVnwBHW1dXY0y/09kSxDHA56paIyJXAz8CaiMXVowoLCFu64cMTfdZQ7Uxpt/pbIL4M9AoIhOBHwClwIMRiypWDJsKLTs5MbvKEoQxpt/pbIJoU1XFTbb3e1X9PZAWubBiRKih+hjfetaW1xMMdpxpxBhj+q7OJog6EbkN+BLw79BU3vGRCytG5IyGpCwmsIrG1gArt+2MdkTGGNNpnU0QlwMtuPEQ23Czsv5vxKKKFSJQOIXC+k8BWLCuKsoBGWNM53UqQYSSwsNAhoicBzSrqrVBdEbhFOKrVjE+O8j7ayujHY0xxnRapxKEiFwGfABcClwGLBSRmZEMLGaE2iEuytvOwvWVBKwdwhjTT3S2iuk/gSmqeq2qXoNbLe7HkQsrhhQcBQjHJa2nrrmNlVutHcIY0z90NkF4VHVHu9eVXTh3YEtMh0FjOaTZTUZr1UzGmP6is1/yL4rISyJynYhcB/ybDrO0mv0onELCtiWMzknk/XWWIIwx/UNnG6m/D8wGJgATgdmq+sNIBhZTRp0KzbVckV/KB+urbGZXY0y/0OlqIlV9UlW/o6q3qOrTkQwq5oyZDgnpnNH2JvUtbSzfYu0Qxpi+b78JQkTqRGRnmEediNi3XGfFJ8K4Cyjc+gqJtFg1kzGmX9hvglDVNFVND/NIU9X0gxVkTJhwOR5/A1dnLbeGamNMv2A9kQ6WEcdBegGXxr/Log1V+K0dwhjTx1mCOFg8HjjiUorrPiCptYp31lREOyJjjNkvSxAH04TL8WiAS5MW8cxHm6MdjTHG7JcliIMpfxzkH8FVSe/z8vLtNLS0RTsiY4zZp4gmCBGZLiKfi8gaEbk1zP7rRKRcRD4OPb7abt+1IrI69Lg2knEeVBMuY1jjSgrbSnl5xbZoR2OMMfsUsQQRWjPiHuBsYBxwhYiMC3Po46o6KfS4L3RuNvAT4GjcvE8/EZGsSMV6UE26EvX6+HryfJ75aEu0ozHGmH2KZAliKrBGVdepaivwGG5Fus44C3hFVatUtRp4BZgeoTgPrpRcZPxFnMebfLh6I+V1LdGOyBhjwopkgigANrV7XRba1tElIrJUROaKyLCunCsiN4rIYhFZXF5e3ltxR96UG0gINDLD8y7PLbVShDGmb4pkgpAw2zouhvAsUKSqE4BXgQe6cC6qOltVS1S1JC8vr0fBHlSFJTB4Al9NfN16Mxlj+qxIJogyYFi714XAHj+XVbVSVXfVsdwLHNXZc/s1EZh6AyMDG/BtXsiq7XXRjsgYY/YSyQSxCCgWkZEi4gNmAfPaHyAiQ9q9nAGsDD1/CThTRLJCjdNnhrbFjsNnEkzI4Lr4V7n3rXXRjsYYY/YSsQShqm3ATbgv9pXAE6q6XETuEJEZocNuFpHlIvIJcDNwXejcKuDnuCSzCLgjtC12+JLxTL6as7wf8N7Hn7KttjnaERljzB5ENTbWSC4pKdHFixdHO4yuqVqP/uEo5rSdxfZj/ovbzxkb7YiMMQOMiCxR1ZJw+2wkdTRlj0QmXM6X4l7jpYVLqW3yRzsiY4z5giWIaDvhu8Tj54rAPB5eWBrtaIwx5guWIKItdzRy+Eyuj3+Fp97+hGZ/INoRGWMMYAmibzjxe/i0lYtanuGfS8qiHY0xxgCWIPqGvENh/EV8Of4VHnr9I1rarBRhjIk+SxB9hJz0AxJp4ZLGJ3hi0aYDn2CMMRFmCaKvGDQWJl7J9XEv8dTr71tbhDEm6ixB9CFyyu14vF6uaf4HTyy2UoQxJrosQfQlGQV4jvkmF3nf5dXXXrZShDEmqixB9DFy/LfxJ2RxY8v9/On11dEOxxgzgFmC6GsSM4g/5Ycc713Oirfm8vGmmmhHZIwZoCxB9EUlXyGQeyi/iP87tz/2Pk2tVtVkjDn4LEH0RXE+vDP+QD6VzKy9nztfWHngc4wxppdZguirhh+NTPkK18e9xMcLXmP+ZzuiHZExZoCxBNGXnfYTSBvMXclz+M6ji1izoz7aERljBhBLEH1ZYjpyzm84JLCBr3uf4YYHF1PbaFOCG2MODksQfd3Y82DC5dyoT5Jb8zHffORD2gLBaEdljBkALEH0B+f8L5JRwN/T7+XjNRv53as2PsIYE3mWIPqDxAy4+F5Sm7Zw/+C5/PnNtXxi4yOMMRFmCaK/GD4NTvw+JTUvcm3ye3z3n7a4kDEmsixB9Ccn/gCKTuBHwb+QX/E+d726KtoRGWNimCWI/sQbB5c/hCd3DHMSf8e7b7/OgnWV0Y7KGBOjIpogRGS6iHwuImtE5Nb9HDdTRFRESkKvi0SkSUQ+Dj3+Esk4+5WkTLh6LvGp2TyY8Gv+8+/P8eKybdGOyhgTgyKWIETEC9wDnA2MA64QkXFhjksDbgYWdti1VlUnhR5fj1Sc/VL6UDxXP0VmAjzg+zW3Pvwms99ai6pGOzJjTAyJZAliKrBGVdepaivwGHBBmON+DvwaaI5gLLFn0GF4Zj1CATt4IvMefvP8p9z5wmfRjsoYE0MimSAKgPbLopWFtn1BRCYDw1T1uTDnjxSRj0TkTRE5IdwbiMiNIrJYRBaXl5f3WuD9RtFxyIV/ZkzTJ/xzyEP89a213P/u+mhHZYyJEXERvLaE2fZFHYiIeIC7gOvCHLcVGK6qlSJyFPCMiIxX1Z17XEx1NjAboKSkZGDWrxwxE2pKmfjaHTySK3z9uUsZmpnEmeMHRzsyY0w/F8kSRBkwrN3rQmBLu9dpwOHAGyKyAZgGzBORElVtUdVKAFVdAqwFxkQw1v7t+O/Aid/nmIZXeSPpB/z7sT/zgfVuMsb0UCQTxCKgWERGiogPmAXM27VTVWtVNVdVi1S1CFgAzFDVxSKSF2rkRkQOAYqBdRGMtX8TgVN/hNwwn/S8Yfze+ztK51zHLY8uYVNVY7SjM8b0UxFLEKraBtwEvASsBJ5Q1eUicoeIzDjA6ScCS0XkE2Au8HVVrYpUrDFj6CTibpxP8zHf4dK4tyhZeSen/nY+dzy7gprG1mhHZ4zpZyRWukaWlJTo4sWLox1G36AKr/wY3vsDr+Vdww1l00lLjOdbpxVz9bQR+OJsfKQxxhGRJapaEm5fJBupTbSIwBk/h+ZaTvvwQRacNIzvbj6JO55bwe9fW80RBRmML0jnpOI8jh2dG+1ojTF9lP2UjFUicN7vYPxFDFrwSx48bCEPfHkq5xwxmNomP3PeWc+V9y3k9qc/panVJv0zxuzNShCxzOOFi+8FVeSVH3PSGXDSxTcD0OwPcNcrq/jrW+tYtL6K288dS4s/wJaaZuK8wmUlw0iM90b5Bowx0WRtEANBwA9PfhVWPOO6xB53MyRlAfD26nK+88QnlNe17HHKYYPTuOvySYwdkh6NiI0xB8n+2iAsQQwUgTb41zdg6eMQlwQTLoNhU2HTBwQ2vEuzP0jpRf8if1A+S8tq+cGTS6lt9PP/Th3N6ePyGZWXao3bxsQgSxBmt61LYdG9sPSf0NbkVqsrnAJr58OkK+CCewCoamjl9qc+5cXlbqbYeK8wMjeFxHgvHhGS4r1cNLmACycXWOIwph+zBGH21lQNddshdwx4PPDqT+Gdu+Dqp2D0aQCoKusqGli+ZScrtuxkbXk9/kCQQFDZVtvM6h31DMlI5PrjikhPjKeivoWaRj8njsnjhOJcRMLNtmKM6UssQZgD8zfDX08AfxN8431ISNvv4arKm6vK+dP8tXywYfcYRp/XQ2sgyBEFGfzHyaM4c1w+cV4rYRjTV1mCMJ2z6QP425kw6SqY/itI7FwD9fqKBuK9Qm5qAiLw9Ieb+cuba9lQ2UiKz8uUkdlMOySHvNQE2oJB2oLKsKxkpo7MDttTqqaxlSWl1QQVThqTZ1VYxkSQJQjTeS//CN77A4gXhk521U3TvuFWsuuCQD530gUAABjqSURBVFB5beV23lpdzoJ1VazZUb/XMQlxHqaOzGZ4djJNrQEaWwOsq6hn1fbdx+amJnBZSSFnjR9MnFdQhfTEeIbnJPf4Vo0xliBMVwSDsOFtWP+W+7NsEaQMgnN+DWNnuAF43VBZ30J9SxtxXg9eEVZu28nbqyp4e3U5lQ2tJPu8JPu8DM5IYmpRFiVF2TS2tvHIwo28/tkOgh3+mR6Sl8L08YM5fnQuXo/gDygegdGDUslLS9ir/aOxtY1nPtrCi8u3ccbYQVx19Ag8HmsjMcYShOm+LR/BvJth21IYczac9UvIGXVQQ9hc08SnZTWAIALbapt5ecU2FqyrItAxcwA5KT7G5KeRm5ZAZlI8AVWe+2QLO5vbyE1NoKK+hSOHZ/Kriydw6OC921q21jZR0+gn3ivEez3kpyfaoEETsyxBmJ4JtMHCP8P8/3aD7qZ8FU76gdu3YwVUl7qqqLSDu0hRdUMry7bU4hH3Re4PBFm1vY6VW3eyekc9NY1+ahpbafIHOG1sPtcdW0TJiCye/mgzv/j3SnY2+ZlSlM3YIekcOjiVdeUNvP7ZDlZ3qA5L8Xk5fVw+5x4xhOOLc0n22QQEJnZYgjC9o26bSxIf/QPEA8G23fviEuGo6+H4bx/0RNEdVQ2t/Gn+GhaXVvPZtp00+4PEe4WpI7M55dBBFGYl4Q8oLW1BlpRW8cKybdQ0+gEYlJbAiJxkBqUnkhjnJSHeg0egtS1Ia1uQltCj2R+gLagk+7yk+OJIjPcS7xXivEKcx4MvzoPP6yHJ52VETjKH5qdRlJtCvPX6MgeRJQjTu3ashI8egtR8yB8HKXnwwb3w8SPgiYMzfgZHf73b7RUHWyCobKxqJC8tgdSE8KUDfyDIe2srWbqphtKqRjZWNlLR0EKL3yWDoCo+r4eEePelnxjvJSHOg8cjNPtdA3xTa8D14goorYEg/kAQf0D3qCaL9wrDs5M5JC+VopxkWtuCVDS0UlXfSpLPS26qj7y0BAZnJFGYmURBVhLJPi+BoOIPKF6PkBjvISneS2pCXNguxsGgdqv9paGljaVltYzMTWFwRmKXzzd9kyUIc3BUrYcXb4NVL7iusufdBXEJ0Y6qz2v2B1hbXs+q7XV8vq2e9RX1rCtvoLSqkcQ4D7mpCWSn+GjyByiva6GyoTVs20tHPq+HQ/JSKM5PIzney7qKetbsqGdncxt5qQnkZyRSmJlEcX4qh+anMTwnmbaA0uQP0OQP0OIP0hoIUt3Qyhuf7+DdtZW0tgUBGJadxJQR2Rw2JI1ReamMyEmhsr6Fz7fXsWZHPSNzUzhvwlDy0rr2+a8rr2fBuio+3VzL8i21tLYF+dZpxUw/fLANvIwQSxDm4AkG4c074c3/cVN4HPNNSMx03WTzDoP4pPDntdTDW792JZBTf9xvSh/REAwq5fUtlFU3UlbdRIs/iNfjqq6CqjT7gzS1Bthe18zq7S7xNLUGGJWXyqhBKWQl+9hR18L2nc1sqmqktKqRA30NDMtO4oyxgzl2VA6lVY0sWl/Fko3Ve03yCJDs89LYGsDrEY4fnUtOqo+NlY1srGqkNRAkxRdHSoKX7BQfw7OTGZ6dTE2jn9c/28G6igYA0hPjOLwgg4r6FlZtr2fqyGy+c8YYCjKTSIz34vN6qG5spaqxlRZ/kMnDM/foSFBW3cjzn27lsMHpHDMqZ49qu4r6FrbVNlPV0EpNk58JBRkU5abscQ/+QBBVwo7BaWp1CX3NjnpqGlspyEqmMCuJ4dnJpOyjBApucOmmqiYGZyT2qbE9liDMwbf8GXjmP8Dfbk3shAw4/GJXuigs2Z0E1s6HZ2+Gmo3u9dm/hqO/dvBjHqB2feGVVTfii3PVY7uqyBLiPCT74hiSkRj2F3xNYytryxvYUNFATqqPQwenMTg9kdU76nnmo838+9OttLYFv0gEST4vDS0BGlraKK9vYWNVI+V1Lfi8HqaNyuH0sYM4sTiPETnJiAhtgSCPL97Eb19eRVXDvpfNTU+M4/yJQzmhOI/nlm7hhWXbvihlZSXHc/rYfOqa2/ikrIattc17nOv1CDOPLOTm04sR4KEFpTz6wUaa/AGmjszhhNG5pCfF8WFpDUs2VrO2vD5sQo33CieNyeP8iUM5Y1z+F50Zmv0Bnv5oM/e/u4HPt9eREOdhYmEmJUVZnDdhKOOGugGpwaDywrJtPPDeBorzU/n6SaMYlu3G+2yoaODpjzaTnhTPRZMLyE7xdeejDssShImOphrYudn92VgBn78AK/7lkobXB8m5brLA8pWQPQpm/MEN0lv9Mlw7D4qOj/YdmIOgsbUNQUjy7bsr8c5mP++urqC+pY0mfwB/QMlMiic7xUdbUPn3UjfGpdkfJC0hjiuOHs4VU4ezansd/166ldc/20FOqo+JhZlMKMxgWHYy2Sk+Unxx/HPJJh5e4H6cBFRRVc4Yl8+QjCTeWVPxxSDPzOR4jhyexYTCDMbkpzF6UCqZyfFsqWmmrLqRjzfW8NzSrWzb2YwIJMd7SfLF0ewPUN/Sxtgh6cw8qpAtNU0sLq1m+eZa2oLKxMIMzj5iCM9+soXlW3YyLDuJ7bUtBFQ5b8IQKupbeHdNJR6BoLpEdMa4fE4oziMvNYHctAQGpyd2u13IEoTpO5p3wspnoeJzaKyEhkoYfASc8B1X/dRcC/ee5iYT/PJLLrFsXuL2HXmdm1jQmDDqmv18tLGGycMzSUuM79K5m2uauO/tdSTEebnq6OFf/HIHNy6mqTXAyNyUA7aDBIPKBxuqeG9tJQ0tbTS2tgHCBZOGcvTI7D3Or2ls5akPN/PYoo2s2l7PsOwkbjl9DBdMKqC8roV7317HIws3kp3i44qpw7i0ZBi1TX4eX7SJpz4sozrUqw5gQmEG827q3g8qSxCmfylfBfeeCq11e26ffDWcf7dbKW8XVWuvMP2aqlJa2cjQzKS92ib8gSBekb16nbUFgmyva6GiroXyuhbi4zycNCavW++/vwRhI35M35M3Bq58zE33MXQyDD0SFv/NNXy3NsJFf4XSd+H9P8LmD+GyB2HkCdGO2phuEZG9Gsl32deYmDivh4LMJAoy99Hpo5dEtLwuItNF5HMRWSMit+7nuJkioiJS0m7bbaHzPheRsyIZp+mDio6HU26HQ8+GtHz3/PSfwfKn4LeHwj8udIsfJWbAQ5fA5y/27P0aq9wocWPMFyJWghARL3APcAZQBiwSkXmquqLDcWnAzcDCdtvGAbOA8cBQ4FURGaOqgUjFa/qB47/tpiD/5DE48ho44lLXPfahi+Hxq1wjd9HxbiZaEbe2hb8RWhtcm0ZjJbTUwZizIPsQd01VN+jv+e9Dah6cfBsccRl4rXBtTMTaIETkGOCnqnpW6PVtAKr6qw7H/Q54Ffge8D1VXdzxWBF5KXSt9/f1ftYGMYA174RHZ7lqp87wxLkEM+2b8Nb/wtLHoOgElzy2fuxW2TvnN3DISZGN25g+IFptEAXApnavy4CjOwQ2GRimqs+JyPc6nLugw7kFHd9ARG4EbgQYPnx4L4Vt+p3EdLj6Sfj8eddGoQHQIMQnu95P8SmQnAXJOe749/4IS+6HxXMAgZNvhxO/5+aXWvksvPYzV211yX0w/sLeiTHQBlVrIe/Q3rmeMQdBJBNEuK4lXxRXRMQD3AVc19Vzv9igOhuYDa4E0a0oTWyIT4LDL+ncsef+Bo69yc0fNeYsGHni7n3jZrjXj1wOc6+Hlp2utNET/mb453VuChIbBGj6kUgmiDJgWLvXhcCWdq/TgMOBN0J9gwcD80RkRifONaZnsorc2hbhJGXCl56Cx78E8/6fG4cxdoZr39jX3FLNtbBpEWx8H1rrYfKXYPDhrkTz+FWw9nXIPwJe+IEryRwxc+9r+JvccYecAj5bMc9EXyTbIOKAVcBpwGZgEXClqi7fx/FvsLsNYjzwCDAV10j9GlC8v0Zqa4Mwva6tFZ7/Lix9AtqaXVVV1gjXMN5at2evp9YGQF0DuTfeHT/yRHeNTQvhgj+6Es4/LoayD+DKx2H06e5cfxMseQDeuQvqt8Gh58LlD4UfFBgMwqoXXTtJ7uiD8tdgYltU2iBUtU1EbgJeArzAHFVdLiJ3AItVdd5+zl0uIk8AK4A24JvWg8kcdHE+1zNq+v+45VdXv+zWxEhIA18KeBN2D9JLzIBhU6GgBAKt8OGD8MFsd/wl9+0uMVzxKNx/LjwyC1JywRMPLbWuBDLieDdX1YI/uQkPT7l9z3jWvQEv/9it7heXBGffCUdeG36gYKANgv59T45oTCfYSGpjIiXgh4YKSB+y5/a67fDe3S4pBAOucXziLDfYTxX+dRN8/JAbAFh8lmt8X3I/rH8TMoa5BvXlT7uEMe4COP/3kJS1+/qNVfDADAi0wI1vuGQWTm0ZVKyGUaf07n2vegkGjYPMYQc+1kSdTbVhTH/S1uJKGduWuVJMcy2kDYVp/wFTb4T4RFfV9N7d8PrPIW0IXPI3GH606/L74AWwfVloedivwLm/3fP6O1bCu7+HT//pVgWc9g0485edm+dq8xKXVGo3uUkYj7oOcot37/90Ljz5FRg03iWnuE7MOlpf7joDHOS1zo1jCcKY/qZuGzx+tRvQN3EWjDxpzzmodilb4npb1Za5QX5rX4OyRXD5w65a7P0/wtVPuTXDWxvhxVvhwwdcF+Ajr3UJYtG9MPZ8uPjefVdJqcJrd8A7/7d7m3hdyeWaZ9yEi9s+hfvOcEvOVq938Zy8zwkUnKZqmH0K1G+HL78IQyZ2/+8sUj573k1Ff/TXYnLeL0sQxsSy5lp49ttuGhLxwMw5MP4i1732rye6AYAz58Bzt0D5Z24RpxO+C8nZ7vz3/wQv3e4avjMKXRtKXAJMvALGXeiu+cIPXCI58lo49mZIHwo7t8AD57vR6ruuH/C7ksPL/+mqwb72FuSPDx93MAiPXu7WA0nOdgMYb3i9b61pXr8D7j7SdUqYeCXMuNt1QlB1f987PoPjb+nXvc4sQRgT61Rh2ZOuAX1Mu6nLtnwE953uSgopeXDxbBh16t7nr3zW9aIC1/het9WVAjKGuyqkta+5xHDGHXv+iq5aDw/OcL+wvT64/gW3GFRDJdwz1bVDfOXV8FOXzP9vNwHjuf/nzpkzHQaNhev+3bnG9YZK12DfVO1KQN6uTfHdKfNudmutH3UtLLoPRp8Bx93sSlNli9wxeYfBzL+79dnD8Tf16c4CliCMGcgW3Qcb3nG9sdLyO3dOMAirX4J374aN78GpP4ITvhe+iqW2zK0eOPkamHDp7u3LnnLVX0UnwLCj3Ze/L9W1N1Sthzf+GyZd7boAi7gk9fjVMHiCK1G01LkxI9Pv3N0+oQofPwzzfwU7y3a/14TL4cK/9O56IVuXuhLYMd90Y2aW3O9KSRqE1Hy3NG76EHj6P9w9nfMbOPJLe15j2ZPw1Nfgwj/BhMs6974tde7v6SBVZ1mCMMZ0X2PV7uqorlCF+b90qwhWrnVToLQ3bBpc8y/X6L7Lovtg0RzX8yohzTWKB9vcl+9h57ov6GVz3bmHnevaPjYucN2Cj70Zzvx5z+61fewPnA/bl8PNH7nBkwBrXnWJY+oNLj5wvdKevtH1KvvSM7t7hbU2wB9KXGnM44UrHoPiM8K/X1uLW3Hxo4dcae2E78Gp/9k793IAliCMMdHV1gKVa1y7SGKGmz8rOffAv/hry+CpG91EjIkZ7tf1ybe7FQh3Ndqrutl4F93rpoQfMtGNaN+61JVais+EwikHnqG3tQF2bnXtDZs+cO0u5/4Wpnz1wPfnb4K/HO8GRn7jPZc83rgT3vgVXPlPmP8LtxDWNf9yvc3AtR2tec0lhtUvQ3ON662Wlu8S0zcWHJSeXZYgjDH9VzAAb//WVUGd/T8w4tjwx8y93pVWwDWsZx/iqrI0AAkZkJIDiNs3dJIbQzL6dFe6WXSvGzHvb9x9zUHjXSN7Z6d+37gQ5pzluhaf8F34w1GuxHDZg64r79+nuwSUkgON1btXTEzKdu1GR8x006w0lLtzR57oBlYeSOVaV8obNqVzcXZgCcIYE/v8za5nUWq+KzEkpruxGuvecI+WOkBdL60N70JTlWuQD7RAXCIcPtNN8e5LdVVcQye7a3TFi7e5kfAFJa4B/ZsfQPZIt69mI7z+C/c8KdsliqITXKwduzC/cxe8+tPdXZSba2HhbHfO5Gt2J61VL8NTX4XUwa7E0Y02GEsQxhjTXqANSt9x1TsZhTDpqu61s3TU2gB/PhaqN8Bx33K9vrqjrQXuOdr1zDruWy5ZNJS7ffmHu5JU6XuuJ9jgw93cXVlF3XorSxDGGHOwlC1xpYjz/s+1m3TXZ8/DY1e454VT4Jz/daWQl/7TjWQH13vrvN/1aByGJQhjjOlvVN3I9bQhMGHW7uqj1kZY+BfXBfjIa3rcHTZaK8oZY4zpLhHX2N2RL9n14joIenFUiTHGmFhiCcIYY0xYliCMMcaEZQnCGGNMWJYgjDHGhGUJwhhjTFiWIIwxxoRlCcIYY0xYMTOSWkTKgdIeXCIXqOilcPqLgXjPMDDveyDeMwzM++7qPY9Q1bxwO2ImQfSUiCze13DzWDUQ7xkG5n0PxHuGgXnfvXnPVsVkjDEmLEsQxhhjwrIEsdvsaAcQBQPxnmFg3vdAvGcYmPfda/dsbRDGGGPCshKEMcaYsCxBGGOMCWvAJwgRmS4in4vIGhG5NdrxRIqIDBOR+SKyUkSWi8i3QtuzReQVEVkd+jMr2rH2NhHxishHIvJc6PVIEVkYuufHRcQX7Rh7m4hkishcEfks9JkfE+uftYjcEvq3vUxEHhWRxFj8rEVkjojsEJFl7baF/WzFuTv0/bZURI7synsN6AQhIl7gHuBsYBxwhYiMi25UEdMGfFdVxwLTgG+G7vVW4DVVLQZeC72ONd8CVrZ7/T/AXaF7rga+EpWoIuv3wIuqehgwEXf/MftZi0gBcDNQoqqHA15gFrH5Wd8PTO+wbV+f7dlAcehxI/DnrrzRgE4QwFRgjaquU9VW4DHggijHFBGqulVVPww9r8N9YRTg7veB0GEPABdGJ8LIEJFC4FzgvtBrAU4F5oYOicV7TgdOBP4GoKqtqlpDjH/WuCWUk0QkDkgGthKDn7WqvgVUddi8r8/2AuBBdRYAmSIypLPvNdATRAGwqd3rstC2mCYiRcBkYCGQr6pbwSURYFD0IouI3wE/AIKh1zlAjaq2hV7H4md+CFAO/D1UtXafiKQQw5+1qm4GfgNsxCWGWmAJsf9Z77Kvz7ZH33EDPUFImG0x3e9XRFKBJ4Fvq+rOaMcTSSJyHrBDVZe03xzm0Fj7zOOAI4E/q+pkoIEYqk4KJ1TnfgEwEhgKpOCqVzqKtc/6QHr0732gJ4gyYFi714XAlijFEnEiEo9LDg+r6lOhzdt3FTlDf+6IVnwRcBwwQ0Q24KoPT8WVKDJD1RAQm595GVCmqgtDr+fiEkYsf9anA+tVtVxV/cBTwLHE/me9y74+2x59xw30BLEIKA71dPDhGrXmRTmmiAjVvf8NWKmq/9du1zzg2tDza4F/HezYIkVVb1PVQlUtwn22r6vqVcB8YGbosJi6ZwBV3QZsEpFDQ5tOA1YQw581rmppmogkh/6t77rnmP6s29nXZzsPuCbUm2kaULurKqozBvxIahE5B/er0gvMUdVfRjmkiBCR44G3gU/ZXR9/O64d4glgOO4/2aWq2rEBrN8TkZOB76nqeSJyCK5EkQ18BFytqi3RjK+3icgkXMO8D1gHXI/7QRizn7WI/Ay4HNdj7yPgq7j69pj6rEXkUeBk3LTe24GfAM8Q5rMNJcs/4no9NQLXq+riTr/XQE8QxhhjwhvoVUzGGGP2wRKEMcaYsCxBGGOMCcsShDHGmLAsQRhjjAnLEoQxfYCInLxrtllj+gpLEMYYY8KyBGFMF4jI1SLygYh8LCJ/Da01US8ivxWRD0XkNRHJCx07SUQWhObhf7rdHP2jReRVEfkkdM6o0OVT263h8HBokJMxUWMJwphOEpGxuJG6x6nqJCAAXIWbGO5DVT0SeBM3shXgQeCHqjoBN4J91/aHgXtUdSJuvqBdUx9MBr6NW5vkENxcUsZETdyBDzHGhJwGHAUsCv24T8JNihYEHg8d8xDwlIhkAJmq+mZo+wPAP0UkDShQ1acBVLUZIHS9D1S1LPT6Y6AIeCfyt2VMeJYgjOk8AR5Q1dv22Cjy4w7H7W/+mv1VG7WfIyiA/f80UWZVTMZ03mvATBEZBF+sAzwC9/9o14yhVwLvqGotUC0iJ4S2fwl4M7QGR5mIXBi6RoKIJB/UuzCmk+wXijGdpKorRORHwMsi4gH8wDdxC/KMF5EluJXMLg+dci3wl1AC2DWjKrhk8VcRuSN0jUsP4m0Y02k2m6sxPSQi9aqaGu04jOltVsVkjDEmLCtBGGOMCctKEMYYY8KyBGGMMSYsSxDGGGPCsgRhjDEmLEsQxhhjwvr/wh1mFixoehMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history['loss'])\n",
    "plt.plot(model.history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(\n",
    "      x=scaled_test\n",
    "    , batch_size=10\n",
    "    , verbose=0\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.92354316, 0.07645684],\n",
       "       [0.5125614 , 0.48743862],\n",
       "       [0.9019646 , 0.09803537],\n",
       "       [0.88093376, 0.11906628],\n",
       "       [0.52436095, 0.47563902],\n",
       "       [0.6480833 , 0.35191673],\n",
       "       [0.42836812, 0.5716318 ],\n",
       "       [0.8942413 , 0.10575875],\n",
       "       [0.2771684 , 0.72283167],\n",
       "       [0.9168642 , 0.08313575],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.6710233 , 0.32897663],\n",
       "       [0.04409792, 0.95590216],\n",
       "       [0.9091869 , 0.09081309],\n",
       "       [0.0424073 , 0.9575927 ],\n",
       "       [0.06378603, 0.93621397],\n",
       "       [0.8816986 , 0.11830144],\n",
       "       [0.8340757 , 0.16592434],\n",
       "       [0.5024387 , 0.4975613 ],\n",
       "       [0.43457478, 0.5654252 ],\n",
       "       [0.6828148 , 0.3171852 ],\n",
       "       [0.36647663, 0.6335233 ],\n",
       "       [0.04089573, 0.9591043 ],\n",
       "       [0.5649417 , 0.4350583 ],\n",
       "       [0.04288247, 0.95711756],\n",
       "       [0.95783514, 0.04216492],\n",
       "       [0.0413801 , 0.95861995],\n",
       "       [0.8471451 , 0.15285495],\n",
       "       [0.64667594, 0.35332403],\n",
       "       [0.9468887 , 0.05311136],\n",
       "       [0.9081556 , 0.09184435],\n",
       "       [0.8957955 , 0.10420454],\n",
       "       [0.67793506, 0.32206488],\n",
       "       [0.7006667 , 0.29933333],\n",
       "       [0.5720196 , 0.4279804 ],\n",
       "       [0.8018801 , 0.19811991],\n",
       "       [0.3975977 , 0.6024023 ],\n",
       "       [0.326084  , 0.67391604],\n",
       "       [0.8671123 , 0.13288766],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.939017  , 0.06098293],\n",
       "       [0.60049015, 0.39950982],\n",
       "       [0.9384701 , 0.06152983],\n",
       "       [0.05603113, 0.9439689 ],\n",
       "       [0.04291718, 0.95708287],\n",
       "       [0.8671123 , 0.13288766],\n",
       "       [0.6663071 , 0.33369288],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.03970155, 0.9602984 ],\n",
       "       [0.5973926 , 0.4026074 ],\n",
       "       [0.5463945 , 0.45360547],\n",
       "       [0.8660399 , 0.13396016],\n",
       "       [0.08118112, 0.9188189 ],\n",
       "       [0.04616978, 0.95383024],\n",
       "       [0.87776625, 0.12223381],\n",
       "       [0.8936118 , 0.10638818],\n",
       "       [0.92525256, 0.07474739],\n",
       "       [0.8671123 , 0.13288766],\n",
       "       [0.93775296, 0.0622471 ],\n",
       "       [0.04084768, 0.95915234],\n",
       "       [0.76291376, 0.23708622],\n",
       "       [0.87712   , 0.12288006],\n",
       "       [0.79184896, 0.20815112],\n",
       "       [0.34307423, 0.6569258 ],\n",
       "       [0.6978827 , 0.30211726],\n",
       "       [0.05980321, 0.9401968 ],\n",
       "       [0.2771684 , 0.72283167],\n",
       "       [0.6756288 , 0.32437122],\n",
       "       [0.5925445 , 0.4074554 ],\n",
       "       [0.05146493, 0.9485351 ],\n",
       "       [0.3646951 , 0.63530487],\n",
       "       [0.8340757 , 0.16592434],\n",
       "       [0.41740605, 0.5825939 ],\n",
       "       [0.5769947 , 0.42300528],\n",
       "       [0.04098246, 0.9590176 ],\n",
       "       [0.6009969 , 0.39900303],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.04357868, 0.9564214 ],\n",
       "       [0.8731312 , 0.12686877],\n",
       "       [0.3646951 , 0.63530487],\n",
       "       [0.43412074, 0.5658793 ],\n",
       "       [0.72521603, 0.27478397],\n",
       "       [0.6845074 , 0.31549254],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.87776625, 0.12223381],\n",
       "       [0.93775296, 0.0622471 ],\n",
       "       [0.39528784, 0.6047122 ],\n",
       "       [0.2771684 , 0.72283167],\n",
       "       [0.3975977 , 0.6024023 ],\n",
       "       [0.3976113 , 0.60238874],\n",
       "       [0.47741133, 0.5225886 ],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.03835365, 0.9616463 ],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.5541097 , 0.44589034],\n",
       "       [0.8671123 , 0.13288766],\n",
       "       [0.04038238, 0.9596177 ],\n",
       "       [0.8935308 , 0.10646927],\n",
       "       [0.30926   , 0.69074   ],\n",
       "       [0.91708446, 0.08291557],\n",
       "       [0.04278584, 0.95721424],\n",
       "       [0.8893227 , 0.11067736],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.8742532 , 0.12574677],\n",
       "       [0.40239382, 0.5976062 ],\n",
       "       [0.88733524, 0.11266477],\n",
       "       [0.8340757 , 0.16592434],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.8134495 , 0.18655051],\n",
       "       [0.8900424 , 0.10995756],\n",
       "       [0.3975977 , 0.6024023 ],\n",
       "       [0.04084768, 0.95915234],\n",
       "       [0.28519973, 0.71480024],\n",
       "       [0.04076913, 0.95923084],\n",
       "       [0.86519176, 0.13480827],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.2155863 , 0.7844137 ],\n",
       "       [0.6205451 , 0.3794549 ],\n",
       "       [0.0679783 , 0.9320217 ],\n",
       "       [0.05032558, 0.9496744 ],\n",
       "       [0.93775296, 0.0622471 ],\n",
       "       [0.04276451, 0.9572355 ],\n",
       "       [0.88733524, 0.11266477],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.26893732, 0.7310626 ],\n",
       "       [0.84282523, 0.15717475],\n",
       "       [0.5929519 , 0.4070481 ],\n",
       "       [0.891429  , 0.10857096],\n",
       "       [0.8594118 , 0.14058827],\n",
       "       [0.9119968 , 0.08800324],\n",
       "       [0.70122427, 0.29877564],\n",
       "       [0.6641625 , 0.33583745],\n",
       "       [0.93775296, 0.0622471 ],\n",
       "       [0.9419711 , 0.05802881],\n",
       "       [0.8594118 , 0.14058827],\n",
       "       [0.87762547, 0.12237456],\n",
       "       [0.86329323, 0.1367068 ],\n",
       "       [0.35483766, 0.6451623 ],\n",
       "       [0.94999355, 0.05000648],\n",
       "       [0.8855686 , 0.11443137],\n",
       "       [0.04127428, 0.9587257 ],\n",
       "       [0.81796336, 0.18203667],\n",
       "       [0.86844015, 0.13155991],\n",
       "       [0.6516459 , 0.34835416],\n",
       "       [0.95217896, 0.04782105],\n",
       "       [0.60049015, 0.39950982],\n",
       "       [0.84282523, 0.15717475],\n",
       "       [0.60049015, 0.39950982],\n",
       "       [0.90175587, 0.09824418],\n",
       "       [0.04104072, 0.9589592 ],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.960133  , 0.03986697],\n",
       "       [0.5973926 , 0.4026074 ],\n",
       "       [0.9098895 , 0.09011053],\n",
       "       [0.8594118 , 0.14058827],\n",
       "       [0.04206138, 0.9579386 ],\n",
       "       [0.35483766, 0.6451623 ],\n",
       "       [0.6516459 , 0.34835416],\n",
       "       [0.44880468, 0.55119526],\n",
       "       [0.3975977 , 0.6024023 ],\n",
       "       [0.48214495, 0.517855  ],\n",
       "       [0.05388184, 0.9461182 ],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.8900424 , 0.10995756],\n",
       "       [0.57047546, 0.42952457],\n",
       "       [0.6801524 , 0.31984758],\n",
       "       [0.88604605, 0.1139539 ],\n",
       "       [0.04089573, 0.9591043 ],\n",
       "       [0.34307423, 0.6569258 ],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.88093376, 0.11906628],\n",
       "       [0.90172946, 0.09827049],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.9549806 , 0.04501941],\n",
       "       [0.05661958, 0.94338036],\n",
       "       [0.05119719, 0.94880277],\n",
       "       [0.67900556, 0.3209944 ],\n",
       "       [0.07600817, 0.92399186],\n",
       "       [0.04535888, 0.9546411 ],\n",
       "       [0.8731312 , 0.12686877],\n",
       "       [0.67986816, 0.32013175],\n",
       "       [0.04522356, 0.9547765 ],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.04048641, 0.9595136 ],\n",
       "       [0.8886779 , 0.11132208],\n",
       "       [0.05442299, 0.945577  ],\n",
       "       [0.89200336, 0.10799666],\n",
       "       [0.95590407, 0.04409591],\n",
       "       [0.8886779 , 0.11132208],\n",
       "       [0.89839655, 0.10160343],\n",
       "       [0.60049015, 0.39950982],\n",
       "       [0.6973831 , 0.30261686],\n",
       "       [0.9017435 , 0.09825658],\n",
       "       [0.4745159 , 0.5254841 ],\n",
       "       [0.91708446, 0.08291557],\n",
       "       [0.30463064, 0.6953693 ],\n",
       "       [0.2771684 , 0.72283167],\n",
       "       [0.84996176, 0.15003826],\n",
       "       [0.43880445, 0.5611955 ],\n",
       "       [0.3975977 , 0.6024023 ],\n",
       "       [0.22583951, 0.77416056],\n",
       "       [0.65121466, 0.3487853 ],\n",
       "       [0.05673929, 0.9432607 ],\n",
       "       [0.859704  , 0.14029601],\n",
       "       [0.60049015, 0.39950982],\n",
       "       [0.43785322, 0.5621467 ],\n",
       "       [0.8559429 , 0.14405717],\n",
       "       [0.04127428, 0.9587257 ],\n",
       "       [0.8671123 , 0.13288766],\n",
       "       [0.9119968 , 0.08800324],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.79611355, 0.20388652],\n",
       "       [0.06732538, 0.93267465],\n",
       "       [0.8973622 , 0.10263778],\n",
       "       [0.6516459 , 0.34835416],\n",
       "       [0.3975977 , 0.6024023 ],\n",
       "       [0.750573  , 0.24942707],\n",
       "       [0.04310946, 0.9568906 ],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.06879612, 0.9312039 ],\n",
       "       [0.8340757 , 0.16592434],\n",
       "       [0.05203839, 0.9479616 ],\n",
       "       [0.8340757 , 0.16592434],\n",
       "       [0.04071444, 0.9592856 ],\n",
       "       [0.59402955, 0.40597042],\n",
       "       [0.851334  , 0.14866605],\n",
       "       [0.3975977 , 0.6024023 ],\n",
       "       [0.9375537 , 0.06244632],\n",
       "       [0.883146  , 0.11685398],\n",
       "       [0.7510118 , 0.2489883 ],\n",
       "       [0.04419415, 0.95580584],\n",
       "       [0.8888848 , 0.11111528],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.6162532 , 0.3837468 ],\n",
       "       [0.8240673 , 0.17593277],\n",
       "       [0.7151696 , 0.2848303 ],\n",
       "       [0.8240673 , 0.17593277],\n",
       "       [0.06297528, 0.9370248 ],\n",
       "       [0.04198888, 0.95801115],\n",
       "       [0.04041322, 0.9595868 ],\n",
       "       [0.07773163, 0.9222684 ],\n",
       "       [0.7126663 , 0.28733367],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.32174966, 0.67825025],\n",
       "       [0.62547857, 0.37452143],\n",
       "       [0.05203839, 0.9479616 ],\n",
       "       [0.9142431 , 0.0857569 ],\n",
       "       [0.0679783 , 0.9320217 ],\n",
       "       [0.5135254 , 0.4864746 ],\n",
       "       [0.06635837, 0.9336416 ],\n",
       "       [0.8240673 , 0.17593277],\n",
       "       [0.55735314, 0.44264686],\n",
       "       [0.8594118 , 0.14058827],\n",
       "       [0.9146197 , 0.08538036],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.88733524, 0.11266477],\n",
       "       [0.0508626 , 0.9491374 ],\n",
       "       [0.8340757 , 0.16592434],\n",
       "       [0.94428   , 0.0557199 ],\n",
       "       [0.8340757 , 0.16592434],\n",
       "       [0.06363073, 0.93636924],\n",
       "       [0.2155863 , 0.7844137 ],\n",
       "       [0.8731312 , 0.12686877],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.60049015, 0.39950982],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.3975977 , 0.6024023 ],\n",
       "       [0.76291376, 0.23708622],\n",
       "       [0.6710233 , 0.32897663],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.04362772, 0.95637226],\n",
       "       [0.5027487 , 0.4972512 ],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.0604087 , 0.9395913 ],\n",
       "       [0.86844015, 0.13155991],\n",
       "       [0.9031058 , 0.09689422],\n",
       "       [0.89372545, 0.10627459],\n",
       "       [0.84280115, 0.15719879],\n",
       "       [0.35483766, 0.6451623 ],\n",
       "       [0.2690146 , 0.7309854 ],\n",
       "       [0.3975977 , 0.6024023 ],\n",
       "       [0.28938973, 0.7106102 ],\n",
       "       [0.22353673, 0.7764633 ],\n",
       "       [0.9281934 , 0.07180662],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.5463945 , 0.45360547],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.60049015, 0.39950982],\n",
       "       [0.42836812, 0.5716318 ],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.7387918 , 0.26120815],\n",
       "       [0.9281934 , 0.07180662],\n",
       "       [0.8742532 , 0.12574677],\n",
       "       [0.06633394, 0.9336661 ],\n",
       "       [0.9468887 , 0.05311136],\n",
       "       [0.58663046, 0.41336948],\n",
       "       [0.8935308 , 0.10646927],\n",
       "       [0.9119968 , 0.08800324],\n",
       "       [0.87776625, 0.12223381],\n",
       "       [0.9042586 , 0.09574141],\n",
       "       [0.8594118 , 0.14058827],\n",
       "       [0.3975977 , 0.6024023 ],\n",
       "       [0.04589433, 0.95410573],\n",
       "       [0.701739  , 0.29826096],\n",
       "       [0.21707594, 0.7829241 ],\n",
       "       [0.7447506 , 0.25524938],\n",
       "       [0.51345265, 0.48654735],\n",
       "       [0.79184896, 0.20815112],\n",
       "       [0.84282523, 0.15717475],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.44081387, 0.5591861 ],\n",
       "       [0.04041322, 0.9595868 ],\n",
       "       [0.26149875, 0.7385012 ],\n",
       "       [0.69015044, 0.30984953],\n",
       "       [0.8180191 , 0.18198088],\n",
       "       [0.88093376, 0.11906628],\n",
       "       [0.8919047 , 0.10809533],\n",
       "       [0.8742532 , 0.12574677],\n",
       "       [0.8671123 , 0.13288766],\n",
       "       [0.86329323, 0.1367068 ],\n",
       "       [0.6038013 , 0.39619875],\n",
       "       [0.04044921, 0.9595508 ],\n",
       "       [0.851334  , 0.14866605],\n",
       "       [0.07063971, 0.92936033],\n",
       "       [0.6710233 , 0.32897663],\n",
       "       [0.89240843, 0.10759153],\n",
       "       [0.83513844, 0.16486153],\n",
       "       [0.0810245 , 0.91897553],\n",
       "       [0.6366413 , 0.36335868],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.46303517, 0.5369648 ],\n",
       "       [0.88093376, 0.11906628],\n",
       "       [0.58663046, 0.41336948],\n",
       "       [0.87712   , 0.12288006],\n",
       "       [0.94167715, 0.05832282],\n",
       "       [0.859704  , 0.14029601],\n",
       "       [0.26828158, 0.7317184 ],\n",
       "       [0.80871713, 0.19128285],\n",
       "       [0.9119968 , 0.08800324],\n",
       "       [0.84543246, 0.15456755],\n",
       "       [0.04220313, 0.9577969 ],\n",
       "       [0.37435645, 0.62564355],\n",
       "       [0.2464002 , 0.7535998 ],\n",
       "       [0.86329323, 0.1367068 ],\n",
       "       [0.4422961 , 0.55770385],\n",
       "       [0.8559429 , 0.14405717],\n",
       "       [0.05661112, 0.9433889 ],\n",
       "       [0.03844878, 0.9615512 ],\n",
       "       [0.859704  , 0.14029601],\n",
       "       [0.80871713, 0.19128285],\n",
       "       [0.92722243, 0.07277756],\n",
       "       [0.27334315, 0.72665685],\n",
       "       [0.6887899 , 0.3112101 ],\n",
       "       [0.04318472, 0.9568153 ],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.5063851 , 0.4936149 ],\n",
       "       [0.96254075, 0.03745921],\n",
       "       [0.06834298, 0.931657  ],\n",
       "       [0.05661112, 0.9433889 ],\n",
       "       [0.88093376, 0.11906628],\n",
       "       [0.04377614, 0.9562239 ],\n",
       "       [0.90705436, 0.09294572],\n",
       "       [0.93775296, 0.0622471 ],\n",
       "       [0.34307423, 0.6569258 ],\n",
       "       [0.03844878, 0.9615512 ],\n",
       "       [0.87080383, 0.12919618],\n",
       "       [0.87588656, 0.12411347],\n",
       "       [0.0416437 , 0.9583563 ],\n",
       "       [0.6845074 , 0.31549254],\n",
       "       [0.89402896, 0.10597103],\n",
       "       [0.04537647, 0.9546235 ],\n",
       "       [0.04005516, 0.9599449 ],\n",
       "       [0.5785914 , 0.42140865],\n",
       "       [0.83513844, 0.16486153],\n",
       "       [0.7086671 , 0.29133284],\n",
       "       [0.79847944, 0.20152058],\n",
       "       [0.9141582 , 0.08584178],\n",
       "       [0.8742532 , 0.12574677],\n",
       "       [0.43880445, 0.5611955 ],\n",
       "       [0.44389156, 0.5561084 ],\n",
       "       [0.87776625, 0.12223381],\n",
       "       [0.07303946, 0.9269605 ],\n",
       "       [0.8594118 , 0.14058827],\n",
       "       [0.900508  , 0.09949201],\n",
       "       [0.8340757 , 0.16592434],\n",
       "       [0.7600832 , 0.23991683],\n",
       "       [0.5406597 , 0.45934033],\n",
       "       [0.03964135, 0.9603587 ],\n",
       "       [0.504893  , 0.495107  ],\n",
       "       [0.896994  , 0.10300595],\n",
       "       [0.95225286, 0.04774711],\n",
       "       [0.04522356, 0.9547765 ],\n",
       "       [0.8594118 , 0.14058827],\n",
       "       [0.0420224 , 0.95797753],\n",
       "       [0.84282523, 0.15717475],\n",
       "       [0.9062461 , 0.09375393],\n",
       "       [0.04183977, 0.95816016],\n",
       "       [0.90167946, 0.09832048],\n",
       "       [0.0413801 , 0.95861995],\n",
       "       [0.49795756, 0.50204235],\n",
       "       [0.63434154, 0.36565846],\n",
       "       [0.82685196, 0.173148  ],\n",
       "       [0.8808605 , 0.11913947],\n",
       "       [0.7296723 , 0.27032763],\n",
       "       [0.3975977 , 0.6024023 ],\n",
       "       [0.23284002, 0.76716   ],\n",
       "       [0.3975977 , 0.6024022 ],\n",
       "       [0.04273545, 0.9572646 ],\n",
       "       [0.40616658, 0.59383345],\n",
       "       [0.9141582 , 0.08584185],\n",
       "       [0.04044921, 0.9595508 ],\n",
       "       [0.93374425, 0.06625573],\n",
       "       [0.9141582 , 0.08584185],\n",
       "       [0.37435654, 0.6256435 ]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "rounded_predictions = np.argmax(predictions, axis=-1)\n",
    "\n",
    "for i in rounded_predictions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= {\"PassengerId\":passID,\"Survived\":rounded_predictions}\n",
    "result = pd.DataFrame(data,columns=[\"PassengerId\",\"Survived\"])\n",
    "result.set_index(\"PassengerId\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(passID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result.to_csv(r'G:\\Kaggle\\Titanic\\Submission2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(r'G:\\Kaggle\\Titanic\\model1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_classifier = SVC(C=10.0, gamma=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.05, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC_classifier.fit(scaled_train_samples, train_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_preds = SVC_classifier.predict(scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_data = {\"PassengerId\":passID, \"Survived\":svc_preds}\n",
    "svc_sub = pd.DataFrame(svc_data, columns=[\"PassengerId\", \"Survived\"])\n",
    "svc_sub.set_index(\"PassengerId\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 1 1 0 1 0\n",
      " 1 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 0 1 1 0 1 1 0\n",
      " 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 1 1 1 1 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(svc_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svc_sub.to_csv(r'G:\\Kaggle\\Titanic\\Submission3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dmatrix = xgb.DMatrix(data=scaled_train_samples,label=train_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective='reg:linear',colsample_bytree=0.3,learning_rate=0.1,max_depth=5,alpha=10,n_estimator=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:06:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.2.0/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:06:28] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:06:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.2.0/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimator=10, n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "             objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "             scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg.fit(scaled_train_samples,train_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = xg_reg.predict(scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1.,\n",
       "       1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
       "       1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1.,\n",
       "       1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0.,\n",
       "       1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
       "       1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
       "       1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
       "       0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rounded_predictions = np.around(pred)\n",
    "rounded_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "418\n"
     ]
    }
   ],
   "source": [
    "print(type(rounded_predictions))\n",
    "print(rounded_predictions.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_data = {\"PassengerId\":passID, \"Survived\":rounded_predictions}\n",
    "svc_sub = pd.DataFrame(svc_data, columns=[\"PassengerId\", \"Survived\"])\n",
    "svc_sub.set_index(\"PassengerId\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_sub.to_csv(r'G:\\Kaggle\\Titanic\\Submission5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
